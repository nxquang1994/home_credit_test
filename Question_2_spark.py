"""
In this task, I assume data from OLTP stored in MySQL DB engine
The spark below read data from MySQL DB and transform to new format with the new designed schema
"""


import os
import pyspark
from pyspark.sql import SparkSession
from pyspark import pandas as ps

# Please get the connector file via this link:
# https://dev.mysql.com/downloads/connector/j/

spark = SparkSession.builder.appName("SQL Tables")\
    .config("spark.jars", "mysql-connector-java.jar")\
    .getOrCreate()


# Format is "jdbc:mysql://localhost:3306/<db_name>"
url = os.environ['OLTP_DB_URL']
driver = "com.mysql.jdbc.Driver"
user = os.environ['OLTP_DB_USER']
password = os.environ['OLTP_DB_PASSWORD']

list_tables = [
    'BRANCH_TYPES',
    'ADDRESSES',
    'BRANCHES',
    'TRANSACTION_TYPES',
    'CUSTOMERS',
    'ACCOUNT_TYPES',
    'STATUSES'
    'ACCOUNT',
    'TRANSACTIONS'
]

dict_spark_df = {}
for table_name in list_tables:
    dict_spark_df[table_name] = spark.read\
        .format("jdbc")\
        .option("driver", driver)\
        .option("url", url)\
        .option("user", user)\
        .option("password", password)\
        .option("dbtable", table_name)\
        .load()

# In this ingestion, we focus to ingest and transform data relate to branch
df_spark_customer_details = dict_spark_df['CUSTOMERS'][['customer_id', 'address_id', 'current_branch_id']]


olap_url = os.environ['OLAP_DB_URL']
olap_driver = "com.mysql.jdbc.Driver"
olap_user = os.environ['OLAP_DB_USER']
olap_password = os.environ['OLAP_DB_PASSWORD']

df_branches = dict_spark_df['BRANCHES'].toPandas()
df_customers = dict_spark_df['CUSTOMERS'].toPandas()

df_customer_details = df_customers[['customer_id', 'address_id', 'current_branch_id']]
df_customers = df_customers[['customer_id', 'date_of_birth', 'description']]


df_customers.to_sql('CUSTOMERS', if_exists='replace')
df_customer_details.to_sql('CUSTOMER_DETAILS', if_exists='replace')

# Note the CUSTOMER_BRANCHES is generated by the trigger: customer_trigger
# as mention in #1








